{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MovieMind - Clustering Analysis\n",
    "\n",
    "This notebook performs k-means clustering to find similar movies and audience patterns.\n",
    "\n",
    "## Contents:\n",
    "1. Data Loading and Preparation\n",
    "2. Feature Engineering\n",
    "3. Elbow Method (Optimal k)\n",
    "4. K-means Clustering\n",
    "5. Silhouette Analysis\n",
    "6. Cluster Interpretation\n",
    "7. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from src.utils.db_manager import DatabaseManager\n",
    "from src.preprocessing.text_processor import TextProcessor\n",
    "from src.models.clustering import MovieClusterer\n",
    "\n",
    "# Settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from database\n",
    "with DatabaseManager() as db:\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        m.movie_id,\n",
    "        m.title,\n",
    "        m.genres,\n",
    "        m.vote_average,\n",
    "        m.vote_count,\n",
    "        m.popularity,\n",
    "        m.runtime,\n",
    "        m.budget,\n",
    "        m.revenue,\n",
    "        m.overview,\n",
    "        m.release_date,\n",
    "        COUNT(r.review_id) as review_count,\n",
    "        AVG(r.sentiment_score) as avg_sentiment\n",
    "    FROM movies m\n",
    "    LEFT JOIN reviews r ON m.movie_id = r.movie_id\n",
    "    GROUP BY m.movie_id, m.title, m.genres, m.vote_average, m.vote_count, \n",
    "             m.popularity, m.runtime, m.budget, m.revenue, m.overview, m.release_date\n",
    "    HAVING COUNT(r.review_id) > 0\n",
    "    LIMIT 1000\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(db.execute_query(query))\n",
    "\n",
    "print(f\"Loaded {len(df)} movies with reviews\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Fill missing values\n",
    "df['runtime'] = df['runtime'].fillna(df['runtime'].median())\n",
    "df['budget'] = df['budget'].fillna(0)\n",
    "df['revenue'] = df['revenue'].fillna(0)\n",
    "df['avg_sentiment'] = df['avg_sentiment'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year from release_date\n",
    "df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')\n",
    "df['year'] = df['release_date'].dt.year\n",
    "df['year'] = df['year'].fillna(df['year'].median())\n",
    "\n",
    "# Create ROI feature\n",
    "df['roi'] = np.where(df['budget'] > 0, (df['revenue'] - df['budget']) / df['budget'], 0)\n",
    "\n",
    "# Create genre features (one-hot encoding for top genres)\n",
    "top_genres = ['Drama', 'Comedy', 'Action', 'Thriller', 'Romance', 'Adventure', 'Horror', 'Crime']\n",
    "\n",
    "for genre in top_genres:\n",
    "    df[f'genre_{genre}'] = df['genres'].apply(\n",
    "        lambda x: 1 if isinstance(x, list) and genre in x else 0\n",
    "    )\n",
    "\n",
    "print(\"Features created:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical features for clustering\n",
    "feature_cols = [\n",
    "    'vote_average', 'vote_count', 'popularity', 'runtime', \n",
    "    'review_count', 'avg_sentiment', 'year', 'roi'\n",
    "] + [f'genre_{g}' for g in top_genres]\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(f\"Feature matrix shape: {X_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Elbow Method (Finding Optimal k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate inertia for different k values\n",
    "K_range = range(2, 11)\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_scaled, kmeans.labels_))\n",
    "    print(f\"k={k}: Inertia={kmeans.inertia_:.2f}, Silhouette={silhouette_scores[-1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot elbow curve\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Elbow plot\n",
    "axes[0].plot(K_range, inertias, 'bo-', linewidth=2, markersize=8)\n",
    "axes[0].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
    "axes[0].set_ylabel('Inertia (Within-cluster sum of squares)', fontsize=12)\n",
    "axes[0].set_title('Elbow Method', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Silhouette plot\n",
    "axes[1].plot(K_range, silhouette_scores, 'ro-', linewidth=2, markersize=8)\n",
    "axes[1].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
    "axes[1].set_ylabel('Silhouette Score', fontsize=12)\n",
    "axes[1].set_title('Silhouette Score by k', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identify optimal k\n",
    "optimal_k = K_range[np.argmax(silhouette_scores)]\n",
    "print(f\"\\nOptimal k based on Silhouette Score: {optimal_k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. K-means Clustering with Optimal k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use optimal k (or set manually if needed)\n",
    "k_final = optimal_k  # You can change this manually if needed (e.g., k_final = 5)\n",
    "\n",
    "# Fit final model\n",
    "kmeans_final = KMeans(n_clusters=k_final, random_state=42, n_init=10)\n",
    "df['cluster'] = kmeans_final.fit_predict(X_scaled)\n",
    "\n",
    "print(f\"Clustering with k={k_final}\")\n",
    "print(f\"\\nCluster distribution:\")\n",
    "print(df['cluster'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Silhouette Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate silhouette scores\n",
    "silhouette_avg = silhouette_score(X_scaled, df['cluster'])\n",
    "sample_silhouette_values = silhouette_samples(X_scaled, df['cluster'])\n",
    "\n",
    "print(f\"Average Silhouette Score: {silhouette_avg:.3f}\")\n",
    "print(f\"\\nSilhouette score by cluster:\")\n",
    "for i in range(k_final):\n",
    "    cluster_silhouette = sample_silhouette_values[df['cluster'] == i]\n",
    "    print(f\"  Cluster {i}: {cluster_silhouette.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silhouette plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "y_lower = 10\n",
    "for i in range(k_final):\n",
    "    cluster_silhouette_values = sample_silhouette_values[df['cluster'] == i]\n",
    "    cluster_silhouette_values.sort()\n",
    "    \n",
    "    size_cluster_i = cluster_silhouette_values.shape[0]\n",
    "    y_upper = y_lower + size_cluster_i\n",
    "    \n",
    "    color = plt.cm.nipy_spectral(float(i) / k_final)\n",
    "    ax.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                      0, cluster_silhouette_values,\n",
    "                      facecolor=color, edgecolor=color, alpha=0.7)\n",
    "    \n",
    "    ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "    y_lower = y_upper + 10\n",
    "\n",
    "ax.set_xlabel(\"Silhouette Coefficient\")\n",
    "ax.set_ylabel(\"Cluster\")\n",
    "ax.set_title(f\"Silhouette Plot for {k_final} Clusters\")\n",
    "ax.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\", label=f\"Avg: {silhouette_avg:.3f}\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cluster Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze cluster characteristics\n",
    "cluster_summary = df.groupby('cluster')[feature_cols].mean()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CLUSTER CHARACTERISTICS (Mean values)\")\n",
    "print(\"=\"*80)\n",
    "display(cluster_summary.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample movies from each cluster\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE MOVIES FROM EACH CLUSTER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for cluster_id in range(k_final):\n",
    "    print(f\"\\n--- Cluster {cluster_id} ({(df['cluster'] == cluster_id).sum()} movies) ---\")\n",
    "    sample = df[df['cluster'] == cluster_id][['title', 'vote_average', 'genres', 'year']].head(5)\n",
    "    for idx, row in sample.iterrows():\n",
    "        genres_str = ', '.join(row['genres']) if isinstance(row['genres'], list) else 'N/A'\n",
    "        print(f\"  â€¢ {row['title']} ({int(row['year'])}) - Rating: {row['vote_average']:.1f} - Genres: {genres_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genre distribution by cluster\n",
    "genre_cluster = pd.DataFrame()\n",
    "for genre in top_genres:\n",
    "    genre_cluster[genre] = df.groupby('cluster')[f'genre_{genre}'].mean() * 100\n",
    "\n",
    "genre_cluster_T = genre_cluster.T\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(genre_cluster_T, annot=True, fmt='.1f', cmap='YlOrRd', \n",
    "            cbar_kws={'label': 'Percentage of Movies'})\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Genre')\n",
    "plt.title('Genre Distribution by Cluster (%)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization (PCA for 2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce to 2D using PCA\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Total variance explained: {pca.explained_variance_ratio_.sum():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot with clusters\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Plot each cluster with different color\n",
    "for i in range(k_final):\n",
    "    cluster_points = X_pca[df['cluster'] == i]\n",
    "    plt.scatter(cluster_points[:, 0], cluster_points[:, 1], \n",
    "                label=f'Cluster {i}', alpha=0.6, s=100)\n",
    "\n",
    "# Plot cluster centers\n",
    "centers_pca = pca.transform(kmeans_final.cluster_centers_)\n",
    "plt.scatter(centers_pca[:, 0], centers_pca[:, 1], \n",
    "            c='black', marker='X', s=500, edgecolors='white', linewidths=2,\n",
    "            label='Centroids', zorder=10)\n",
    "\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)', fontsize=12)\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)', fontsize=12)\n",
    "plt.title('Movie Clusters (PCA Visualization)', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CLUSTERING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Number of clusters: {k_final}\")\n",
    "print(f\"Average Silhouette Score: {silhouette_avg:.3f}\")\n",
    "print(f\"Total movies clustered: {len(df)}\")\n",
    "print(f\"\\nCluster sizes:\")\n",
    "for i in range(k_final):\n",
    "    count = (df['cluster'] == i).sum()\n",
    "    percentage = count / len(df) * 100\n",
    "    print(f\"  Cluster {i}: {count} movies ({percentage:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
